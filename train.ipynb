{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models.initializers import he_init\n",
    "from models.losses import MeanSquaredError, CrossEntropyLoss\n",
    "from models.activations import ReLU, Softmax, Sigmoid\n",
    "from models.network import NeuralNetwork\n",
    "from models.layers import DenseLayer\n",
    "from load_data import load_fashion_mnist\n",
    "from utils import one_hot_encode, save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_fashion_mnist()\n",
    "y_train_one_hot = one_hot_encode(y_train, 10)\n",
    "y_test_one_hot = one_hot_encode(y_test, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T16:19:39.508859600Z",
     "start_time": "2023-11-26T16:19:38.890490900Z"
    }
   },
   "id": "44474b676b7f33a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Autoencoder 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b79e9ad6bc20b9f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.126\n",
      "Epoch: 2, Loss: 0.082\n",
      "Epoch: 3, Loss: 0.074\n",
      "Epoch: 4, Loss: 0.062\n",
      "Epoch: 5, Loss: 0.056\n",
      "Epoch: 6, Loss: 0.057\n",
      "Epoch: 7, Loss: 0.047\n",
      "Epoch: 8, Loss: 0.045\n",
      "Epoch: 9, Loss: 0.040\n",
      "Epoch: 10, Loss: 0.040\n",
      "Epoch: 11, Loss: 0.040\n",
      "Epoch: 12, Loss: 0.038\n",
      "Epoch: 13, Loss: 0.041\n",
      "Epoch: 14, Loss: 0.035\n",
      "Epoch: 15, Loss: 0.034\n",
      "Epoch: 16, Loss: 0.035\n",
      "Epoch: 17, Loss: 0.033\n",
      "Epoch: 18, Loss: 0.034\n",
      "Epoch: 19, Loss: 0.031\n",
      "Epoch: 20, Loss: 0.033\n",
      "Epoch: 21, Loss: 0.032\n",
      "Epoch: 22, Loss: 0.031\n",
      "Epoch: 23, Loss: 0.029\n",
      "Epoch: 24, Loss: 0.031\n",
      "Epoch: 25, Loss: 0.030\n",
      "Epoch: 26, Loss: 0.027\n",
      "Epoch: 27, Loss: 0.028\n",
      "Epoch: 28, Loss: 0.028\n",
      "Epoch: 29, Loss: 0.027\n",
      "Epoch: 30, Loss: 0.030\n",
      "Epoch: 31, Loss: 0.026\n",
      "Epoch: 32, Loss: 0.027\n",
      "Epoch: 33, Loss: 0.026\n",
      "Epoch: 34, Loss: 0.024\n",
      "Epoch: 35, Loss: 0.027\n",
      "Epoch: 36, Loss: 0.027\n",
      "Epoch: 37, Loss: 0.024\n",
      "Epoch: 38, Loss: 0.025\n",
      "Epoch: 39, Loss: 0.026\n",
      "Epoch: 40, Loss: 0.026\n",
      "Epoch: 41, Loss: 0.025\n",
      "Epoch: 42, Loss: 0.025\n",
      "Epoch: 43, Loss: 0.025\n",
      "Epoch: 44, Loss: 0.026\n",
      "Epoch: 45, Loss: 0.025\n",
      "Epoch: 46, Loss: 0.024\n",
      "Epoch: 47, Loss: 0.025\n",
      "Epoch: 48, Loss: 0.022\n",
      "Epoch: 49, Loss: 0.025\n",
      "Epoch: 50, Loss: 0.022\n",
      "Epoch: 51, Loss: 0.025\n",
      "Epoch: 52, Loss: 0.022\n",
      "Epoch: 53, Loss: 0.024\n",
      "Epoch: 54, Loss: 0.023\n",
      "Epoch: 55, Loss: 0.023\n",
      "Epoch: 56, Loss: 0.022\n",
      "Epoch: 57, Loss: 0.021\n",
      "Epoch: 58, Loss: 0.022\n",
      "Epoch: 59, Loss: 0.024\n",
      "Epoch: 60, Loss: 0.020\n",
      "Epoch: 61, Loss: 0.023\n",
      "Epoch: 62, Loss: 0.020\n",
      "Epoch: 63, Loss: 0.022\n",
      "Epoch: 64, Loss: 0.024\n",
      "Epoch: 65, Loss: 0.023\n",
      "Epoch: 66, Loss: 0.022\n",
      "Epoch: 67, Loss: 0.021\n",
      "Epoch: 68, Loss: 0.022\n",
      "Epoch: 69, Loss: 0.022\n",
      "Epoch: 70, Loss: 0.021\n",
      "Epoch: 71, Loss: 0.019\n",
      "Epoch: 72, Loss: 0.022\n",
      "Epoch: 73, Loss: 0.021\n",
      "Epoch: 74, Loss: 0.021\n",
      "Epoch: 75, Loss: 0.021\n",
      "Epoch: 76, Loss: 0.020\n",
      "Epoch: 77, Loss: 0.022\n",
      "Epoch: 78, Loss: 0.021\n",
      "Epoch: 79, Loss: 0.022\n",
      "Epoch: 80, Loss: 0.021\n",
      "Epoch: 81, Loss: 0.023\n",
      "Epoch: 82, Loss: 0.020\n",
      "Epoch: 83, Loss: 0.018\n",
      "Epoch: 84, Loss: 0.019\n",
      "Epoch: 85, Loss: 0.021\n",
      "Epoch: 86, Loss: 0.021\n",
      "Epoch: 87, Loss: 0.021\n",
      "Epoch: 88, Loss: 0.020\n",
      "Epoch: 89, Loss: 0.020\n",
      "Epoch: 90, Loss: 0.021\n",
      "Epoch: 91, Loss: 0.019\n",
      "Epoch: 92, Loss: 0.020\n",
      "Epoch: 93, Loss: 0.019\n",
      "Epoch: 94, Loss: 0.019\n",
      "Epoch: 95, Loss: 0.018\n",
      "Epoch: 96, Loss: 0.020\n",
      "Epoch: 97, Loss: 0.021\n",
      "Epoch: 98, Loss: 0.019\n",
      "Epoch: 99, Loss: 0.020\n",
      "Epoch: 100, Loss: 0.020\n"
     ]
    }
   ],
   "source": [
    "autoencoder = NeuralNetwork()\n",
    "autoencoder.add_layer(DenseLayer(784, 256, activation_fn=ReLU(), initializer=he_init))\n",
    "autoencoder.add_layer(DenseLayer(256, 64, activation_fn=ReLU(), initializer=he_init))\n",
    "autoencoder.add_layer(DenseLayer(64, 256, activation_fn=ReLU(), initializer=he_init))\n",
    "autoencoder.add_layer(DenseLayer(256, 784, activation_fn=Sigmoid(), initializer=he_init))\n",
    "\n",
    "autoencoder.train(x_train, x_train, loss_function=MeanSquaredError(), epochs=100, batch_size=100, learning_rate=0.15)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T16:34:08.611071300Z",
     "start_time": "2023-11-26T16:20:36.872706700Z"
    }
   },
   "id": "7206355b07994da6"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "save_model(autoencoder, 'trained_models/autoencoder1.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T16:34:48.523181200Z",
     "start_time": "2023-11-26T16:34:48.459840Z"
    }
   },
   "id": "f71ed607589fb28f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Autoencoder (Regularized)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46a5e7b4751349d0"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.139\n",
      "Epoch: 2, Loss: 0.096\n",
      "Epoch: 3, Loss: 0.095\n",
      "Epoch: 4, Loss: 0.087\n",
      "Epoch: 5, Loss: 0.088\n",
      "Epoch: 6, Loss: 0.088\n",
      "Epoch: 7, Loss: 0.082\n",
      "Epoch: 8, Loss: 0.071\n",
      "Epoch: 9, Loss: 0.069\n",
      "Epoch: 10, Loss: 0.066\n",
      "Epoch: 11, Loss: 0.061\n",
      "Epoch: 12, Loss: 0.062\n",
      "Epoch: 13, Loss: 0.052\n",
      "Epoch: 14, Loss: 0.056\n",
      "Epoch: 15, Loss: 0.047\n",
      "Epoch: 16, Loss: 0.051\n",
      "Epoch: 17, Loss: 0.048\n",
      "Epoch: 18, Loss: 0.046\n",
      "Epoch: 19, Loss: 0.047\n",
      "Epoch: 20, Loss: 0.043\n",
      "Epoch: 21, Loss: 0.045\n",
      "Epoch: 22, Loss: 0.047\n",
      "Epoch: 23, Loss: 0.045\n",
      "Epoch: 24, Loss: 0.042\n",
      "Epoch: 25, Loss: 0.038\n",
      "Epoch: 26, Loss: 0.045\n",
      "Epoch: 27, Loss: 0.043\n",
      "Epoch: 28, Loss: 0.043\n",
      "Epoch: 29, Loss: 0.040\n",
      "Epoch: 30, Loss: 0.042\n",
      "Epoch: 31, Loss: 0.038\n",
      "Epoch: 32, Loss: 0.042\n",
      "Epoch: 33, Loss: 0.041\n",
      "Epoch: 34, Loss: 0.040\n",
      "Epoch: 35, Loss: 0.042\n",
      "Epoch: 36, Loss: 0.040\n",
      "Epoch: 37, Loss: 0.040\n",
      "Epoch: 38, Loss: 0.043\n",
      "Epoch: 39, Loss: 0.038\n",
      "Epoch: 40, Loss: 0.041\n",
      "Epoch: 41, Loss: 0.040\n",
      "Epoch: 42, Loss: 0.040\n",
      "Epoch: 43, Loss: 0.041\n",
      "Epoch: 44, Loss: 0.040\n",
      "Epoch: 45, Loss: 0.037\n",
      "Epoch: 46, Loss: 0.040\n",
      "Epoch: 47, Loss: 0.045\n",
      "Epoch: 48, Loss: 0.035\n",
      "Epoch: 49, Loss: 0.040\n",
      "Epoch: 50, Loss: 0.040\n",
      "Epoch: 51, Loss: 0.039\n",
      "Epoch: 52, Loss: 0.044\n",
      "Epoch: 53, Loss: 0.039\n",
      "Epoch: 54, Loss: 0.040\n",
      "Epoch: 55, Loss: 0.038\n",
      "Epoch: 56, Loss: 0.042\n",
      "Epoch: 57, Loss: 0.036\n",
      "Epoch: 58, Loss: 0.041\n",
      "Epoch: 59, Loss: 0.038\n",
      "Epoch: 60, Loss: 0.039\n",
      "Epoch: 61, Loss: 0.042\n",
      "Epoch: 62, Loss: 0.039\n",
      "Epoch: 63, Loss: 0.039\n",
      "Epoch: 64, Loss: 0.042\n",
      "Epoch: 65, Loss: 0.045\n",
      "Epoch: 66, Loss: 0.039\n",
      "Epoch: 67, Loss: 0.037\n",
      "Epoch: 68, Loss: 0.040\n",
      "Epoch: 69, Loss: 0.039\n",
      "Epoch: 70, Loss: 0.039\n",
      "Epoch: 71, Loss: 0.037\n",
      "Epoch: 72, Loss: 0.036\n",
      "Epoch: 73, Loss: 0.037\n",
      "Epoch: 74, Loss: 0.038\n",
      "Epoch: 75, Loss: 0.042\n",
      "Epoch: 76, Loss: 0.039\n",
      "Epoch: 77, Loss: 0.035\n",
      "Epoch: 78, Loss: 0.037\n",
      "Epoch: 79, Loss: 0.040\n",
      "Epoch: 80, Loss: 0.039\n",
      "Epoch: 81, Loss: 0.037\n",
      "Epoch: 82, Loss: 0.043\n",
      "Epoch: 83, Loss: 0.039\n",
      "Epoch: 84, Loss: 0.038\n",
      "Epoch: 85, Loss: 0.038\n",
      "Epoch: 86, Loss: 0.040\n",
      "Epoch: 87, Loss: 0.041\n",
      "Epoch: 88, Loss: 0.038\n",
      "Epoch: 89, Loss: 0.041\n",
      "Epoch: 90, Loss: 0.039\n",
      "Epoch: 91, Loss: 0.041\n",
      "Epoch: 92, Loss: 0.035\n",
      "Epoch: 93, Loss: 0.040\n",
      "Epoch: 94, Loss: 0.039\n",
      "Epoch: 95, Loss: 0.042\n",
      "Epoch: 96, Loss: 0.037\n",
      "Epoch: 97, Loss: 0.038\n",
      "Epoch: 98, Loss: 0.037\n",
      "Epoch: 99, Loss: 0.037\n",
      "Epoch: 100, Loss: 0.038\n"
     ]
    }
   ],
   "source": [
    "autoencoder2 = NeuralNetwork()\n",
    "autoencoder2.add_layer(DenseLayer(784, 256, activation_fn=ReLU(), initializer=he_init, l2_reg=0.0001))\n",
    "autoencoder2.add_layer(DenseLayer(256, 64, activation_fn=ReLU(), initializer=he_init, l2_reg=0.0001))\n",
    "autoencoder2.add_layer(DenseLayer(64, 256, activation_fn=ReLU(), initializer=he_init, l2_reg=0.0001))\n",
    "autoencoder2.add_layer(DenseLayer(256, 784, activation_fn=Sigmoid(), initializer=he_init))\n",
    "\n",
    "autoencoder2.train(x_train, x_train, loss_function=MeanSquaredError(), epochs=100, batch_size=100, learning_rate=0.15)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T17:08:30.398900500Z",
     "start_time": "2023-11-26T16:50:53.875139800Z"
    }
   },
   "id": "f85c20259a966e38"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "save_model(autoencoder2, 'trained_models/autoencoder1_regularized.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T17:09:18.281023400Z",
     "start_time": "2023-11-26T17:09:18.236787900Z"
    }
   },
   "id": "e305f64e55c44ef4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Classifier (input is Fashion MNIST data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9140583faed8c32c"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.413\n",
      "Epoch: 2, Loss: 0.263\n",
      "Epoch: 3, Loss: 0.323\n",
      "Epoch: 4, Loss: 0.450\n",
      "Epoch: 5, Loss: 0.311\n",
      "Epoch: 6, Loss: 0.330\n",
      "Epoch: 7, Loss: 0.202\n",
      "Epoch: 8, Loss: 0.330\n",
      "Epoch: 9, Loss: 0.186\n",
      "Epoch: 10, Loss: 0.268\n",
      "Epoch: 11, Loss: 0.270\n",
      "Epoch: 12, Loss: 0.238\n",
      "Epoch: 13, Loss: 0.273\n",
      "Epoch: 14, Loss: 0.170\n",
      "Epoch: 15, Loss: 0.265\n"
     ]
    }
   ],
   "source": [
    "classifier = NeuralNetwork()\n",
    "classifier.add_layer(DenseLayer(784, 256, activation_fn=ReLU(), initializer=he_init, l2_reg=0.0001))\n",
    "classifier.add_layer(DenseLayer(256, 64, activation_fn=ReLU(), initializer=he_init, l2_reg=0.0001))\n",
    "classifier.add_layer(DenseLayer(64, 10, activation_fn=Softmax(), initializer=he_init))\n",
    "\n",
    "classifier.train(x_train, y_train_one_hot, loss_function=CrossEntropyLoss(), epochs=15, batch_size=100,\n",
    "                 learning_rate=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T18:01:05.381049Z",
     "start_time": "2023-11-26T18:00:01.631085700Z"
    }
   },
   "id": "1e987f74c358546e"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "save_model(classifier, 'trained_models/classifier1.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T18:01:50.880608Z",
     "start_time": "2023-11-26T18:01:50.837295300Z"
    }
   },
   "id": "80e1056d9addc0d9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Classifier (input is encoded Fashion MNIST data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b2339bd84474d07"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.542\n",
      "Epoch: 2, Loss: 0.968\n",
      "Epoch: 3, Loss: 1.086\n",
      "Epoch: 4, Loss: 0.660\n",
      "Epoch: 5, Loss: 0.675\n",
      "Epoch: 6, Loss: 0.694\n",
      "Epoch: 7, Loss: 0.583\n",
      "Epoch: 8, Loss: 0.721\n",
      "Epoch: 9, Loss: 0.666\n",
      "Epoch: 10, Loss: 0.697\n",
      "Epoch: 11, Loss: 0.523\n",
      "Epoch: 12, Loss: 0.601\n",
      "Epoch: 13, Loss: 0.557\n",
      "Epoch: 14, Loss: 0.378\n",
      "Epoch: 15, Loss: 0.806\n",
      "Epoch: 16, Loss: 0.556\n",
      "Epoch: 17, Loss: 0.491\n",
      "Epoch: 18, Loss: 0.407\n",
      "Epoch: 19, Loss: 0.428\n",
      "Epoch: 20, Loss: 0.454\n",
      "Epoch: 21, Loss: 0.444\n",
      "Epoch: 22, Loss: 0.649\n",
      "Epoch: 23, Loss: 0.466\n",
      "Epoch: 24, Loss: 0.415\n",
      "Epoch: 25, Loss: 0.539\n",
      "Epoch: 26, Loss: 0.469\n",
      "Epoch: 27, Loss: 0.502\n",
      "Epoch: 28, Loss: 0.433\n",
      "Epoch: 29, Loss: 0.467\n",
      "Epoch: 30, Loss: 0.513\n",
      "Epoch: 31, Loss: 0.505\n",
      "Epoch: 32, Loss: 0.461\n",
      "Epoch: 33, Loss: 0.404\n",
      "Epoch: 34, Loss: 0.407\n",
      "Epoch: 35, Loss: 0.543\n",
      "Epoch: 36, Loss: 0.499\n",
      "Epoch: 37, Loss: 0.471\n",
      "Epoch: 38, Loss: 0.482\n",
      "Epoch: 39, Loss: 0.391\n",
      "Epoch: 40, Loss: 0.312\n",
      "Epoch: 41, Loss: 0.294\n",
      "Epoch: 42, Loss: 0.362\n",
      "Epoch: 43, Loss: 0.534\n",
      "Epoch: 44, Loss: 0.412\n",
      "Epoch: 45, Loss: 0.312\n",
      "Epoch: 46, Loss: 0.428\n",
      "Epoch: 47, Loss: 0.629\n",
      "Epoch: 48, Loss: 0.535\n",
      "Epoch: 49, Loss: 0.413\n",
      "Epoch: 50, Loss: 0.621\n",
      "Epoch: 51, Loss: 0.591\n",
      "Epoch: 52, Loss: 0.430\n",
      "Epoch: 53, Loss: 0.538\n",
      "Epoch: 54, Loss: 0.387\n",
      "Epoch: 55, Loss: 0.478\n",
      "Epoch: 56, Loss: 0.315\n",
      "Epoch: 57, Loss: 0.334\n",
      "Epoch: 58, Loss: 0.377\n",
      "Epoch: 59, Loss: 0.541\n",
      "Epoch: 60, Loss: 0.363\n",
      "Epoch: 61, Loss: 0.587\n",
      "Epoch: 62, Loss: 0.318\n",
      "Epoch: 63, Loss: 0.338\n",
      "Epoch: 64, Loss: 0.446\n",
      "Epoch: 65, Loss: 0.378\n",
      "Epoch: 66, Loss: 0.331\n",
      "Epoch: 67, Loss: 0.322\n",
      "Epoch: 68, Loss: 0.300\n",
      "Epoch: 69, Loss: 0.529\n",
      "Epoch: 70, Loss: 0.452\n",
      "Epoch: 71, Loss: 0.342\n",
      "Epoch: 72, Loss: 0.421\n",
      "Epoch: 73, Loss: 0.440\n",
      "Epoch: 74, Loss: 0.590\n",
      "Epoch: 75, Loss: 0.284\n",
      "Epoch: 76, Loss: 0.326\n",
      "Epoch: 77, Loss: 0.548\n",
      "Epoch: 78, Loss: 0.369\n",
      "Epoch: 79, Loss: 0.371\n",
      "Epoch: 80, Loss: 0.516\n",
      "Epoch: 81, Loss: 0.456\n",
      "Epoch: 82, Loss: 0.427\n",
      "Epoch: 83, Loss: 0.375\n",
      "Epoch: 84, Loss: 0.425\n",
      "Epoch: 85, Loss: 0.336\n",
      "Epoch: 86, Loss: 0.396\n",
      "Epoch: 87, Loss: 0.374\n",
      "Epoch: 88, Loss: 0.438\n",
      "Epoch: 89, Loss: 0.496\n",
      "Epoch: 90, Loss: 0.379\n",
      "Epoch: 91, Loss: 0.480\n",
      "Epoch: 92, Loss: 0.463\n",
      "Epoch: 93, Loss: 0.356\n",
      "Epoch: 94, Loss: 0.353\n",
      "Epoch: 95, Loss: 0.427\n",
      "Epoch: 96, Loss: 0.545\n",
      "Epoch: 97, Loss: 0.403\n",
      "Epoch: 98, Loss: 0.416\n",
      "Epoch: 99, Loss: 0.451\n",
      "Epoch: 100, Loss: 0.390\n"
     ]
    }
   ],
   "source": [
    "autoencoder.forward(x_train)\n",
    "encoded_x_train = autoencoder.layers[1].outputs\n",
    "\n",
    "classifier2 = NeuralNetwork()\n",
    "classifier2.add_layer(DenseLayer(64, 150, activation_fn=ReLU(), initializer=he_init))\n",
    "classifier2.add_layer(DenseLayer(150, 150, activation_fn=ReLU(), initializer=he_init))\n",
    "classifier2.add_layer(DenseLayer(150, 10, activation_fn=Softmax(), initializer=he_init))\n",
    "\n",
    "classifier2.train(encoded_x_train, y_train_one_hot, loss_function=CrossEntropyLoss(), epochs=100, batch_size=100,\n",
    "                  learning_rate=0.001)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T18:03:26.776720200Z",
     "start_time": "2023-11-26T18:01:57.026428Z"
    }
   },
   "id": "3a2fd0078da6d022"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "save_model(classifier2, 'trained_models/classifier1_from_encoded.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T18:03:58.277479700Z",
     "start_time": "2023-11-26T18:03:58.224692900Z"
    }
   },
   "id": "80f0559c378bb996"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
